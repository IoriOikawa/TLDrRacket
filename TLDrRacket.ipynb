{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b98656b3-043d-4ad3-bb0a-b93bd30306fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    with open(\"./.env\", \"r\") as mykey:        \n",
    "        os.environ[\"GOOGLE_API_KEY\"] = mykey.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f6dea1-5c4f-4520-a9fc-43492f17a23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_PATH = \"./data/\"\n",
    "\n",
    "def load_pdfs():\n",
    "    if not os.path.exists(DATA_PATH):\n",
    "        raise FileNotFoundError(f\"The directory '{DATA_PATH}' does not exist.\")\n",
    "    \n",
    "    #pdf_loader = PyPDFDirectoryLoader(DATA_PATH)    \n",
    "    documents = []\n",
    "    for pdf_path in tqdm(os.listdir(DATA_PATH)):\n",
    "        try:\n",
    "            if pdf_path.endswith(\".pdf\"):\n",
    "                loader = PyPDFDirectoryLoader(DATA_PATH, pdf_path)\n",
    "                documents.extend(loader.load())\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {pdf_path}: {e}\")\n",
    "    return documents\n",
    "\n",
    "def load_text():\n",
    "    text_loader = TextLoader(\"./data/5400Notes.txt\")\n",
    "    return text_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a6978a-d459-40d3-9094-58da74303edc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.document import Document\n",
    "\n",
    "def split_pdfs(documents: list[Document]):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 800,\n",
    "        chunk_overlap = 80,\n",
    "        length_function = len,\n",
    "        is_separator_regex = False,\n",
    "    )\n",
    "    return text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac3505b0-ea3f-4c99-853c-600b558a4d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector Database\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "CHROMA_PATH = \"chroma\"\n",
    "\n",
    "def calculate_chunk_ids(chunks):\n",
    "\n",
    "    # This will create IDs like \"data/monopoly.pdf:6:2\"\n",
    "    # Page Source : Page Number : Chunk Index\n",
    "\n",
    "    last_page_id = None\n",
    "    current_chunk_index = 0\n",
    "\n",
    "    for chunk in tqdm(chunks):\n",
    "        source = chunk.metadata.get(\"source\")\n",
    "        page = chunk.metadata.get(\"page\")\n",
    "        current_page_id = f\"{source}:{page}\"\n",
    "\n",
    "        # If the page ID is the same as the last one, increment the index.\n",
    "        if current_page_id == last_page_id:\n",
    "            current_chunk_index += 1\n",
    "        else:\n",
    "            current_chunk_index = 0\n",
    "\n",
    "        # Calculate the chunk ID.\n",
    "        chunk_id = f\"{current_page_id}:{current_chunk_index}\"\n",
    "        last_page_id = current_page_id\n",
    "\n",
    "        # Add it to the page meta-data.\n",
    "        chunk.metadata[\"id\"] = chunk_id\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def add_to_chroma(chunks: list[Document]):\n",
    "    # Load the existing database.\n",
    "    db = Chroma(\n",
    "        persist_directory=CHROMA_PATH, embedding_function=get_embedding_function()\n",
    "    )\n",
    "\n",
    "    # Calculate Page IDs.\n",
    "    chunks_with_ids = calculate_chunk_ids(chunks)\n",
    "\n",
    "    # Add or Update the documents.\n",
    "    existing_items = db.get(include=[])  # IDs are always included by default\n",
    "    existing_ids = set(existing_items[\"ids\"])\n",
    "    print(f\"Number of existing documents in DB: {len(existing_ids)}\")\n",
    "\n",
    "    # Only add documents that don't exist in the DB.\n",
    "    new_chunks = []\n",
    "    for chunk in tqdm(chunks_with_ids):\n",
    "        if chunk.metadata[\"id\"] not in existing_ids:\n",
    "            new_chunks.append(chunk)\n",
    "\n",
    "    if len(new_chunks):\n",
    "        print(f\"Adding new documents: {len(new_chunks)}\")\n",
    "        new_chunk_ids = [chunk.metadata[\"id\"] for chunk in new_chunks]\n",
    "        db.add_documents(new_chunks, ids=new_chunk_ids)\n",
    "    else:\n",
    "        print(\"No new documents to add\")\n",
    "\n",
    "\n",
    "def clear_database():\n",
    "    if os.path.exists(CHROMA_PATH):\n",
    "        shutil.rmtree(CHROMA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50a11773-7648-4b59-a949-e09371e86f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.embeddings.ollama import OllamaEmbeddings\n",
    "# from langchain_community.embeddings.bedrock import BedrockEmbeddings\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "# Embedding Function: Used when creating the DB, or making a query.\n",
    "def get_embedding_function():\n",
    "    # Bedrock Embeddings for AWS Deploy\n",
    "    # embeddings = BedrockEmbeddings(\n",
    "    #    credentials_profile_name=\"default\", region_name=\"us-east-1\"\n",
    "    #)\n",
    "    # Ollama Embeddings for Local Run\n",
    "    # Install and 'ollama pull llama2|mistral' to deploy.\n",
    "    # Use 'ollama serve' for restful API\n",
    "    # embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "    # \n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50e63b8-11ad-4110-a93c-212312d8526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfs = load_pdfs()\n",
    "# print(pdfs[0])\n",
    "chunks = split_pdfs(pdfs)\n",
    "# print(len(chunks))\n",
    "add_to_chroma(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14296d43-adab-4f4c-a64d-96881721655f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided text, `eq?` checks for pointer equality at a low level, exposing implementation details of Racket and contracts.  `eqv?` (and therefore `equal?`) compares numbers considering both exactness and numerical equality, unlike `=` which converts inexact numbers to exact before comparing.  For characters, `eqv?` and `equal?` behave the same as `char=?`, which performs a case-sensitive comparison.  `char-ci=?` ignores case.  If `eq?` returns true, the two values behave identically in all respects.\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_rag(\"What's the differences between eq? and equal?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef87d75-5750-42ea-9d30-bc6609456ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.ollama import Ollama\n",
    "\n",
    "EVAL_PROMPT = \"\"\"\n",
    "Expected Response: {expected_response}\n",
    "Actual Response: {actual_response}\n",
    "---\n",
    "(Answer with 'true' or 'false') Does the actual response match the expected response? \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def test_lambda_rules():\n",
    "    assert query_and_validate(\n",
    "        question=\"How to write a lambda in Racket?\",\n",
    "        expected_response=\"(lambda())\",\n",
    "    )\n",
    "\n",
    "\n",
    "def test_ticket_to_ride_rules():\n",
    "    assert query_and_validate(\n",
    "        question=\"What function is similar to equal?\",\n",
    "        expected_response=\"eq?\",\n",
    "    )\n",
    "\n",
    "\n",
    "def query_and_validate(question: str, expected_response: str):\n",
    "    response_text = query_rag(question)\n",
    "    prompt = EVAL_PROMPT.format(\n",
    "        expected_response=expected_response, actual_response=response_text\n",
    "    )\n",
    "\n",
    "    model = Ollama(model=\"mistral\")\n",
    "    evaluation_results_str = model.invoke(prompt)\n",
    "    evaluation_results_str_cleaned = evaluation_results_str.strip().lower()\n",
    "\n",
    "    print(prompt)\n",
    "\n",
    "    if \"true\" in evaluation_results_str_cleaned:\n",
    "        # Print response in Green if it is correct.\n",
    "        print(\"\\033[92m\" + f\"Response: {evaluation_results_str_cleaned}\" + \"\\033[0m\")\n",
    "        return True\n",
    "    elif \"false\" in evaluation_results_str_cleaned:\n",
    "        # Print response in Red if it is incorrect.\n",
    "        print(\"\\033[91m\" + f\"Response: {evaluation_results_str_cleaned}\" + \"\\033[0m\")\n",
    "        return False\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Invalid evaluation result. Cannot determine if 'true' or 'false'.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5f267a-6f45-42d2-9a59-cc2464bd769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cli():\n",
    "    # Create CLI.\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"query_text\", type=str, help=\"The query text.\")\n",
    "    args = parser.parse_args()\n",
    "    query_text = args.query_text\n",
    "    query_rag(query_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bb0a80-4dc7-4f66-95bd-497b41cf2874",
   "metadata": {},
   "outputs": [],
   "source": [
    "cli()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a50f27-5d57-4cbe-9b09-49b693048af5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
